{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = !echo $HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{home[0]}/learning-mlops/cc-fraud/data/creditcard.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -9.08530061e-03 -4.86273988e-04 ... -1.40662094e-04\n",
      "   9.99658439e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  3.14200001e-01  7.01632379e-02 ...  3.88161797e-03\n",
      "   7.09143734e-01  0.00000000e+00]\n",
      " [ 2.64054194e-03 -3.58679087e-03 -3.53875680e-03 ... -1.57777241e-04\n",
      "   9.99867610e-01  0.00000000e+00]\n",
      " ...\n",
      " [ 9.99999922e-01  1.11093644e-05 -1.74348810e-06 ... -1.53719162e-07\n",
      "   3.92851325e-04  0.00000000e+00]\n",
      " [ 9.99999998e-01 -1.39153210e-06  3.07013515e-06 ...  6.04977321e-07\n",
      "   5.78743893e-05  0.00000000e+00]\n",
      " [ 9.99999211e-01 -3.08701850e-06 -1.09804382e-06 ...  7.89903674e-08\n",
      "   1.25584419e-03  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# normalize the values of each column\n",
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer(norm='l2')\n",
    "print(normalizer.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data for analysis\n",
    "legit = df[df['Class'] == 0]\n",
    "fraud = df[df['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270070</th>\n",
       "      <td>163909.0</td>\n",
       "      <td>0.618522</td>\n",
       "      <td>-2.413957</td>\n",
       "      <td>-3.109262</td>\n",
       "      <td>0.227243</td>\n",
       "      <td>0.553497</td>\n",
       "      <td>0.589756</td>\n",
       "      <td>1.307842</td>\n",
       "      <td>-0.140266</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614233</td>\n",
       "      <td>0.332566</td>\n",
       "      <td>-0.622175</td>\n",
       "      <td>-1.561293</td>\n",
       "      <td>-0.092206</td>\n",
       "      <td>0.209239</td>\n",
       "      <td>-0.173748</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>718.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142095</th>\n",
       "      <td>84576.0</td>\n",
       "      <td>-0.602596</td>\n",
       "      <td>-0.400060</td>\n",
       "      <td>1.881058</td>\n",
       "      <td>-2.650088</td>\n",
       "      <td>-0.878650</td>\n",
       "      <td>-0.391474</td>\n",
       "      <td>-0.600599</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>-1.870473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124827</td>\n",
       "      <td>-0.014159</td>\n",
       "      <td>-0.365783</td>\n",
       "      <td>-0.517489</td>\n",
       "      <td>0.483876</td>\n",
       "      <td>-0.112338</td>\n",
       "      <td>0.298066</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70792</th>\n",
       "      <td>54023.0</td>\n",
       "      <td>-0.363064</td>\n",
       "      <td>1.141080</td>\n",
       "      <td>1.196409</td>\n",
       "      <td>-0.139387</td>\n",
       "      <td>0.331187</td>\n",
       "      <td>-0.444363</td>\n",
       "      <td>0.677214</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>-0.786455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220951</td>\n",
       "      <td>-0.554252</td>\n",
       "      <td>-0.075876</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>-0.111947</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>0.247414</td>\n",
       "      <td>0.087089</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53565</th>\n",
       "      <td>46047.0</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>-0.494761</td>\n",
       "      <td>1.767898</td>\n",
       "      <td>-1.960268</td>\n",
       "      <td>-1.474040</td>\n",
       "      <td>-0.556345</td>\n",
       "      <td>-0.628335</td>\n",
       "      <td>0.079381</td>\n",
       "      <td>-2.356645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117860</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>-0.126503</td>\n",
       "      <td>0.517471</td>\n",
       "      <td>-0.084368</td>\n",
       "      <td>-0.101974</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>0.016774</td>\n",
       "      <td>20.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145620</th>\n",
       "      <td>87098.0</td>\n",
       "      <td>1.990857</td>\n",
       "      <td>-0.859943</td>\n",
       "      <td>-0.558411</td>\n",
       "      <td>-1.454411</td>\n",
       "      <td>-1.084967</td>\n",
       "      <td>-0.903124</td>\n",
       "      <td>-0.734683</td>\n",
       "      <td>-0.023247</td>\n",
       "      <td>2.078254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337122</td>\n",
       "      <td>1.210272</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.136613</td>\n",
       "      <td>-0.071305</td>\n",
       "      <td>-0.061161</td>\n",
       "      <td>0.024610</td>\n",
       "      <td>-0.053942</td>\n",
       "      <td>16.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "270070  163909.0  0.618522 -2.413957 -3.109262  0.227243  0.553497  0.589756   \n",
       "142095   84576.0 -0.602596 -0.400060  1.881058 -2.650088 -0.878650 -0.391474   \n",
       "70792    54023.0 -0.363064  1.141080  1.196409 -0.139387  0.331187 -0.444363   \n",
       "53565    46047.0 -0.024605 -0.494761  1.767898 -1.960268 -1.474040 -0.556345   \n",
       "145620   87098.0  1.990857 -0.859943 -0.558411 -1.454411 -1.084967 -0.903124   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "270070  1.307842 -0.140266  0.024433  ...  0.614233  0.332566 -0.622175   \n",
       "142095 -0.600599  0.146113 -1.870473  ... -0.124827 -0.014159 -0.365783   \n",
       "70792   0.677214  0.036650 -0.786455  ... -0.220951 -0.554252 -0.075876   \n",
       "53565  -0.628335  0.079381 -2.356645  ...  0.117860  0.635597 -0.126503   \n",
       "145620 -0.734683 -0.023247  2.078254  ...  0.337122  1.210272  0.048681   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "270070 -1.561293 -0.092206  0.209239 -0.173748  0.020481  718.05      0  \n",
       "142095 -0.517489  0.483876 -0.112338  0.298066  0.119481    6.00      0  \n",
       "70792  -0.020508 -0.111947  0.071310  0.247414  0.087089    4.99      0  \n",
       "53565   0.517471 -0.084368 -0.101974  0.055747  0.016774   20.55      0  \n",
       "145620  0.136613 -0.071305 -0.061161  0.024610 -0.053942   16.31      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Under-Sampling (building sample dataset containing similar distribution of normal transactions and Fraudulent Transactions)\n",
    "legit_sample = legit.sample(n=492)\n",
    "# Concatenating two DataFrames\n",
    "new_df = pd.concat([legit_sample, fraud], axis=0)\n",
    "# Print first 5 rows of the new dataset\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(data, target):\n",
    "    # Dictionary to store LabelEncoders for each categorical column\n",
    "    label_encoders = {}\n",
    "\n",
    "    # split the data into X and y\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "\n",
    "    # split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # # Scaling Data\n",
    "    # scaler = MinMaxScaler()\n",
    "    # X_train = scaler.fit_transform(X_train)\n",
    "    # X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Define the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=0,class_weight='balanced')\n",
    "\n",
    "    # Define hyperparameters for tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and parameters\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print('Best Hyperparameters:')\n",
    "    print(best_params)\n",
    "\n",
    "    # Train the model on the full training set\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_rf = best_rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "    print(f'Accuracy on Test Set: {accuracy:.2f}')\n",
    "    print(f'Precision on Test Set: {precision:.2f}')\n",
    "    print(f'Recall on Test Set: {recall:.2f}')\n",
    "    \n",
    "    #visulalizing the confusion matrix\n",
    "    LABELS = ['Normal', 'Fraud'] \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_rf) \n",
    "    plt.figure(figsize =(12, 12)) \n",
    "    sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "    plt.title(\"Confusion matrix\") \n",
    "    plt.ylabel('True class') \n",
    "    plt.xlabel('Predicted class') \n",
    "    plt.show()\n",
    "\n",
    "    return best_rf_model, best_params, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_random_forest(df, \u001b[39m'\u001b[39;49m\u001b[39mClass\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Perform GridSearchCV for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(rf_model, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Get the best model and parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-788918582048-default.cs-us-east1-rtep.cloudshell.dev/home/andrub818/learning-mlops/cc-fraud/cc-model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m best_rf_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    835\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[1;32m    837\u001b[0m         all_more_results)\n\u001b[1;32m    839\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 841\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    843\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    845\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1296\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1295\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:795\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    791\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    793\u001b[0m               n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits))\n\u001b[0;32m--> 795\u001b[0m out \u001b[39m=\u001b[39m parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[1;32m    796\u001b[0m                                        X, y,\n\u001b[1;32m    797\u001b[0m                                        train\u001b[39m=\u001b[39;49mtrain, test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    798\u001b[0m                                        parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    799\u001b[0m                                        split_progress\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    800\u001b[0m                                            split_idx,\n\u001b[1;32m    801\u001b[0m                                            n_splits),\n\u001b[1;32m    802\u001b[0m                                        candidate_progress\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    803\u001b[0m                                            cand_idx,\n\u001b[1;32m    804\u001b[0m                                            n_candidates),\n\u001b[1;32m    805\u001b[0m                                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs)\n\u001b[1;32m    806\u001b[0m                \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters),\n\u001b[1;32m    807\u001b[0m                    (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    808\u001b[0m                    \u001b[39menumerate\u001b[39;49m(candidate_params),\n\u001b[1;32m    809\u001b[0m                    \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))))\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    813\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    814\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 222\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:598\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    597\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    600\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    601\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:387\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    377\u001b[0m trees \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    378\u001b[0m                               random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    379\u001b[0m          \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)]\n\u001b[1;32m    381\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m trees \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    388\u001b[0m                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m'\u001b[39;49m))(\n\u001b[1;32m    389\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    390\u001b[0m         t, \u001b[39mself\u001b[39;49m, X, y, sample_weight, i, \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    391\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    392\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap)\n\u001b[1;32m    393\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees))\n\u001b[1;32m    395\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 222\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:169\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    166\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, y,\n\u001b[1;32m    167\u001b[0m                                                     indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 169\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    170\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:903\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    867\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    868\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \n\u001b[1;32m    870\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    904\u001b[0m         X, y,\n\u001b[1;32m    905\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    906\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    907\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted)\n\u001b[1;32m    908\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:394\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(splitter, min_samples_split,\n\u001b[1;32m    387\u001b[0m                                    min_samples_leaf,\n\u001b[1;32m    388\u001b[0m                                    min_weight_leaf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    392\u001b[0m                                    min_impurity_split)\n\u001b[0;32m--> 394\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    397\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_random_forest(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
